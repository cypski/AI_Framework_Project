{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "plt.rcParams['font.family'] = 'Cambria'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length_results = pd.read_csv()\n",
    "sentiment_results = pd.read_csv()\n",
    "word_counts_results = pd.read_csv()\n",
    "reg_length_results = pd.read_csv()\n",
    "reg_sentiment_results = pd.read_csv()\n",
    "reg_word_counts_results = pd.read_csv()\n",
    "\n",
    "reg_length_results = pd.concat([reg_length_results, length_results], ignore_index = True)\n",
    "reg_sentiment_results = pd.concat([reg_sentiment_results, sentiment_results], ignore_index = True)   \n",
    "reg_word_counts_results = pd.concat([reg_word_counts_results, word_counts_results], ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_sentiment_results['Framework'] = reg_sentiment_results['Filename'].str.split('_').str[0]\n",
    "reg_sentiment_results['Date'] = reg_sentiment_results['Filename'].str.split('_').str[1]\n",
    "new_order = ['Filename', 'Framework', 'Date', 'Positive', 'Negative', 'Neutral']\n",
    "reg_sentiment_results = reg_sentiment_results[new_order]\n",
    "\n",
    "frontier_mapping = {\n",
    "    'Amazon': 2, 'Anthropic': 1, 'Cohere': 1,\n",
    "    'Deepmind': 1, 'Deloitte': 2, 'G42': 2,\n",
    "    'Grammarly': 2, 'IBM': 2, 'KPMG': 2, 'Magic': 2,\n",
    "    'META': 1, 'Microsoft': 1,'Naver': 1, 'NVDIA': 2,\n",
    "    'OpenAI': 1, 'PaloAlto': 2, 'PwC': 2, 'xAI': 1,\n",
    "    'AIVerify': 0, 'ATI': 0, 'CSA': 0, 'DoS': 0,\n",
    "    'HMG': 0, 'ISOIEC': 0, 'NIST': 0, 'OECD': 0, \n",
    "    'UNESCO': 0, 'WEF': 0\n",
    "}\n",
    "\n",
    "reg_sentiment_results['Frontier'] = reg_sentiment_results['Framework'].map(frontier_mapping)\n",
    "reg_sentiment_results['Frontier'] = reg_sentiment_results['Frontier'].astype(int)\n",
    "reg_sentiment_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "another_mapping_scheme_ik = {\n",
    "    0: 'AI Governance and Standards Bodies',\n",
    "    1: 'Frontier AI Firms',\n",
    "    2: 'AI-Adopting/Enterprise AI Companies'\n",
    "}\n",
    "rsr_table = reg_sentiment_results.groupby('Frontier')[['Positive', 'Negative', 'Neutral']].mean().round(2).reset_index()\n",
    "rsr_table['Frontier'] = rsr_table['Frontier'].map(another_mapping_scheme_ik)\n",
    "rsr_table = rsr_table.rename(columns = {'Frontier' : 'Publishing Entity'})\n",
    "apply_percentage_sign = ['Positive', 'Negative', 'Neutral']\n",
    "rsr_table[apply_percentage_sign] = rsr_table[apply_percentage_sign].applymap(lambda x: f\"{x:.2f}%\")\n",
    "rsr_table = rsr_table.style.set_table_styles(\n",
    "    [\n",
    "        {'selector': 'th', 'props': [('font-family', 'Cambria'), ('font-size', '12px')]}, # header\n",
    "        {'selector': 'td', 'props': [('font-family', 'Cambria'), ('font-size', '12px')]}  # cells\n",
    "    ]\n",
    ")\n",
    "rsr_table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_results_sorted = reg_sentiment_results.sort_values(by = 'Positive', ascending = [False])\n",
    "\n",
    "norm = mcolors.Normalize(vmin = -30, vmax = 130) \n",
    "colors = cm.Blues(norm(sentiment_results_sorted['Positive']))\n",
    "\n",
    "plt.figure(figsize = (10, 6), dpi = 500)\n",
    "plt.barh(sentiment_results_sorted['Framework'], sentiment_results_sorted['Positive'], color = colors)\n",
    "plt.xlabel('Positive Sentiment (%)')\n",
    "plt.ylabel('Framework')\n",
    "plt.title('Frameworks by Magnitude of Positive-Coded Language')\n",
    "plt.xlim(0, 100)\n",
    "plt.gca().invert_yaxis()  \n",
    "\n",
    "# plt.savefig()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_results_sorted = reg_sentiment_results.sort_values(by = ['Frontier', 'Positive'], ascending = [True, False])\n",
    "\n",
    "norm = mcolors.Normalize(vmin = -30, vmax = 130)  \n",
    "colors = cm.Blues(norm(sentiment_results_sorted['Positive'])) \n",
    "\n",
    "plt.figure(figsize = (10, 6), dpi = 500)\n",
    "plt.barh(sentiment_results_sorted['Framework'], sentiment_results_sorted['Positive'], color=colors)\n",
    "plt.xlabel('Positive Sentiment (%)')\n",
    "plt.ylabel('Framework')\n",
    "plt.title('Frameworks by Magnitude of Positive-Coded Language (Grouped by Frontier)')\n",
    "plt.xlim(0, 100)\n",
    "plt.gca().invert_yaxis() \n",
    "\n",
    "plt.axhline(y = 9.5, color = 'black', linestyle = '--', linewidth = 0.8, alpha = 0.5)\n",
    "plt.axhline(y = 17.5, color = 'black', linestyle = '--', linewidth = 0.8, alpha = 0.5)\n",
    "\n",
    "# plt.savefig()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_results_sorted = reg_sentiment_results.sort_values(by = 'Negative', ascending = [False])\n",
    "\n",
    "norm = mcolors.Normalize(vmin = -30, vmax = 130) \n",
    "colors = cm.Reds(norm(sentiment_results_sorted['Negative']))  \n",
    "\n",
    "plt.figure(figsize = (10, 6), dpi = 500)\n",
    "plt.barh(sentiment_results_sorted['Framework'], sentiment_results_sorted['Negative'], color = colors)\n",
    "plt.xlabel('Negative Sentiment (%)')\n",
    "plt.ylabel('Framework')\n",
    "plt.title('Frameworks by Magnitude of Negative-Coded Language')\n",
    "plt.xlim(0, 100)\n",
    "plt.gca().invert_yaxis()  \n",
    "\n",
    "# plt.savefig()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_results_sorted = reg_sentiment_results.sort_values(by = ['Frontier', 'Negative'], ascending = [True, False])\n",
    "\n",
    "norm = mcolors.Normalize(vmin = -30, vmax = 130) \n",
    "colors = cm.Reds(norm(sentiment_results_sorted['Negative'])) \n",
    "\n",
    "plt.figure(figsize = (10, 6), dpi = 500)\n",
    "plt.barh(sentiment_results_sorted['Framework'], sentiment_results_sorted['Negative'], color = colors)\n",
    "plt.xlabel('Negative Sentiment (%)')\n",
    "plt.ylabel('Framework')\n",
    "plt.title('Frameworks by Magnitude of Negative-Coded Language (Grouped by Frontier)')\n",
    "plt.xlim(0, 100)\n",
    "plt.gca().invert_yaxis()\n",
    "\n",
    "plt.axhline(y = 9.5, color = 'black', linestyle = '--', linewidth = 0.8, alpha = 0.5)\n",
    "plt.axhline(y = 17.5, color = 'black', linestyle = '--', linewidth = 0.8, alpha = 0.5)\n",
    "\n",
    "# plt.savefig()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_results_sorted = reg_sentiment_results.sort_values(by = 'Neutral', ascending = [False])\n",
    "\n",
    "# Normalize the Positive values for the colormap\n",
    "norm = mcolors.Normalize(vmin = -30, vmax = 130)  \n",
    "colors = cm.Grays(norm(sentiment_results_sorted['Neutral']))  \n",
    "\n",
    "plt.figure(figsize = (10, 6), dpi = 500)\n",
    "plt.barh(sentiment_results_sorted['Framework'], sentiment_results_sorted['Neutral'], color = colors)\n",
    "plt.xlabel('Neutral Sentiment (%)')\n",
    "plt.ylabel('Framework')\n",
    "plt.title('Frameworks by Magnitude of Neutral-Aggregated Language')\n",
    "plt.xlim(0, 100)\n",
    "plt.gca().invert_yaxis()  \n",
    "\n",
    "# plt.savefig()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_results_sorted = reg_sentiment_results.sort_values(by = ['Frontier', 'Neutral'], ascending = [True, False])\n",
    "\n",
    "norm = mcolors.Normalize(vmin = -30, vmax = 130)  \n",
    "colors = cm.Grays(norm(sentiment_results_sorted['Neutral'])) \n",
    "\n",
    "plt.figure(figsize = (10, 6), dpi = 500)\n",
    "plt.barh(sentiment_results_sorted['Framework'], sentiment_results_sorted['Neutral'], color = colors)\n",
    "plt.xlabel('Neutral Sentiment (%)')\n",
    "plt.ylabel('Framework')\n",
    "plt.title('Frameworks by Magnitude of Neutral-Aggregated Language (Grouped)')\n",
    "plt.xlim(0, 100)\n",
    "plt.gca().invert_yaxis() \n",
    "\n",
    "plt.axhline(y = 9.5, color = 'black', linestyle = '--', linewidth = 0.8, alpha = 0.5)\n",
    "plt.axhline(y = 17.5, color = 'black', linestyle = '--', linewidth = 0.8, alpha = 0.5)\n",
    "\n",
    "# plt.savefig()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_sentiment_results['Intensity'] = reg_sentiment_results['Positive'] + reg_sentiment_results['Negative']\n",
    "\n",
    "sentiment_results_sorted = reg_sentiment_results.sort_values(by = 'Intensity', ascending = [False])\n",
    "\n",
    "norm = mcolors.Normalize(vmin = -30, vmax = 130)  \n",
    "colors = cm.Purples(norm(sentiment_results_sorted['Intensity']))  \n",
    "\n",
    "plt.figure(figsize = (10, 6), dpi = 500)\n",
    "plt.barh(sentiment_results_sorted['Framework'], sentiment_results_sorted['Intensity'], color = colors)\n",
    "plt.xlabel('Intensity Sentiment (%)')\n",
    "plt.ylabel('Framework')\n",
    "plt.title('Frameworks by Magnitude of Intense-Aggregated Language')\n",
    "plt.xlim(0, 100)\n",
    "plt.gca().invert_yaxis()  \n",
    "\n",
    "# plt.savefig()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_results_sorted = reg_sentiment_results.sort_values(by = ['Frontier', 'Intensity'], ascending = [True, False])\n",
    "\n",
    "norm = mcolors.Normalize(vmin = -30, vmax = 130) \n",
    "colors = cm.Purples(norm(sentiment_results_sorted['Intensity']))\n",
    "\n",
    "plt.figure(figsize = (10, 6), dpi = 500)\n",
    "plt.barh(sentiment_results_sorted['Framework'], sentiment_results_sorted['Intensity'], color = colors)\n",
    "plt.xlabel('Intense Sentiment (%)')\n",
    "plt.ylabel('Framework')\n",
    "plt.title('Frameworks by Magnitude of Intense-Aggregated Language (Grouped)')\n",
    "plt.xlim(0, 100)\n",
    "plt.gca().invert_yaxis() \n",
    "\n",
    "plt.axhline(y = 9.5, color = 'black', linestyle = '--', linewidth = 0.8, alpha = 0.5)\n",
    "plt.axhline(y = 17.5, color = 'black', linestyle = '--', linewidth = 0.8, alpha = 0.5)\n",
    "\n",
    "# plt.savefig()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_word_counts_results['Framework'] = reg_word_counts_results['Filename'].str.split('_').str[0]\n",
    "reg_word_counts_results['Date'] = reg_word_counts_results['Filename'].str.split('_').str[1]\n",
    "new_order = ['Filename', 'Framework', 'Date', \"risk\", \"safe\", \"bias\", \"security\", \"ethic\",\n",
    "                      \"accountab\", \"transparen\", \"explainab\", \"policy\",\n",
    "                      \"compliance\", \"governance\", \"protect\", \"sustainab\",\n",
    "                      \"fair\", \"catastroph\", \"responsib\", \"prepare\"]\n",
    "reg_word_counts_results = reg_word_counts_results[new_order]\n",
    "\n",
    "reg_word_counts_results = reg_word_counts_results.merge(reg_length_results, on = 'Filename')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_0_frameworks = ['AiVerify', 'ATI', 'CSA', 'DoS', 'HMG', 'ISOIEC', 'NIST', 'OECD', 'UNESCO', 'WEF']\n",
    "group_1_frameworks = ['Anthropic', 'Cohere', 'Deepmind', 'OpenAI', 'Naver', 'META', 'xAI', 'Microsoft']\n",
    "group_2_frameworks = ['Deloitte', 'G42', 'Grammarly', 'IBM', 'KPMG', 'Magic', 'NVDIA', 'PaloAlto', 'PwC', 'Amazon']\n",
    "\n",
    "group_0_results = reg_word_counts_results[reg_word_counts_results['Framework'].isin(group_0_frameworks)]\n",
    "group_1_results = reg_word_counts_results[reg_word_counts_results['Framework'].isin(group_1_frameworks)]\n",
    "group_2_results = reg_word_counts_results[reg_word_counts_results['Framework'].isin(group_2_frameworks)]\n",
    "\n",
    "word_totals_group_0 = group_0_results.iloc[:, 3:].sum(axis = 0).reset_index()\n",
    "word_totals_group_0.columns = ['Word', 'Total']\n",
    "word_totals_group_0 = word_totals_group_0[word_totals_group_0['Word'] != 'Length'] \n",
    "word_totals_group_0_sorted = word_totals_group_0.sort_values(by = 'Total', ascending = False)\n",
    "\n",
    "word_totals_group_1 = group_1_results.iloc[:, 3:].sum(axis = 0).reset_index()\n",
    "word_totals_group_1.columns = ['Word', 'Total']\n",
    "word_totals_group_1 = word_totals_group_1[word_totals_group_1['Word'] != 'Length'] \n",
    "word_totals_group_1_sorted = word_totals_group_1.sort_values(by = 'Total', ascending = False)\n",
    "\n",
    "word_totals_group_2 = group_2_results.iloc[:, 3:].sum(axis = 0).reset_index()\n",
    "word_totals_group_2.columns = ['Word', 'Total']\n",
    "word_totals_group_2 = word_totals_group_2[word_totals_group_2['Word'] != 'Length']\n",
    "word_totals_group_2_sorted = word_totals_group_2.sort_values(by = 'Total', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_mapping = {\n",
    "    'risk': 'Risk', \n",
    "    'security': 'Security',\n",
    "    'safe': 'Safe/Safety',\n",
    "    'responsib': 'Responsible/Responsibility',\n",
    "    'ethic': 'Ethics/Ethical',\n",
    "    'transparen': 'Transparent/Transparency',\n",
    "    'governance': 'Governance',\n",
    "    'policy': 'Policy/Policymaker',\n",
    "    'bias': 'Bias',\n",
    "    'protect': 'Protect/Protection',\n",
    "    'compliance': 'Compliance',\n",
    "    'catastroph': 'Catastrophe/Catastrophic',\n",
    "    'fair': 'Fair/Fairness',\n",
    "    'prepare': 'Prepare/Preparedness',\n",
    "    'accountab': 'Accountable/Accountability',\n",
    "    'explainab': 'Explainable/Explainability',\n",
    "    'sustainab': 'Sustainable/Sustainability',\n",
    "}\n",
    "\n",
    "word_totals_group_0_sorted['Word'] = word_totals_group_0_sorted['Word'].replace(word_mapping)\n",
    "word_totals_group_1_sorted['Word'] = word_totals_group_1_sorted['Word'].replace(word_mapping)\n",
    "word_totals_group_2_sorted['Word'] = word_totals_group_2_sorted['Word'].replace(word_mapping)\n",
    "\n",
    "plt.figure(figsize = (12, 6), dpi = 500, constrained_layout = True)\n",
    "plt.bar(word_totals_group_0_sorted['Word'], word_totals_group_0_sorted['Total'], color = 'mediumaquamarine', alpha = .8)\n",
    "plt.xticks(rotation = 45, ha = 'right')\n",
    "plt.xlabel('Word')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Word Usage (AI Governance and Standards Bodies)')\n",
    "\n",
    "# plt.savefig()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12, 6), dpi = 500, constrained_layout = True)\n",
    "plt.bar(word_totals_group_1_sorted['Word'], word_totals_group_1_sorted['Total'], color = 'mediumseagreen', alpha = .8)\n",
    "plt.xticks(rotation = 45, ha = 'right')\n",
    "plt.xlabel('Word')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Word Usage (Frontier AI Companies)')\n",
    "\n",
    "# plt.savefig()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12, 6), dpi = 500, constrained_layout = True)\n",
    "plt.bar(word_totals_group_2_sorted['Word'], word_totals_group_2_sorted['Total'], color = 'seagreen', alpha = .8)\n",
    "plt.xticks(rotation = 45, ha = 'right')\n",
    "plt.xlabel('Word')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Term Usage (AI-Adopting/Enterprise AI Companies)')\n",
    "\n",
    "# plt.savefig()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melt the DataFrame to reshape it\n",
    "melted_df = reg_word_counts_results.melt(\n",
    "    id_vars=[\"Filename\", \"Framework\", \"Date\", 'Length'], \n",
    "    var_name=\"Word\", \n",
    "    value_name=\"Count\"\n",
    ")\n",
    "\n",
    "melted_df['Word'] = melted_df['Word'].replace(word_mapping)\n",
    "\n",
    "melted_df['Normalised_Count'] = melted_df['Count'] / melted_df['Length']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frontier_mapping = {\n",
    "    'Amazon': 2, 'Anthropic': 1, 'Cohere': 1,\n",
    "    'Deepmind': 1, 'Deloitte': 2, 'G42': 2,\n",
    "    'Grammarly': 2, 'IBM': 2, 'KPMG': 2, 'Magic': 2,\n",
    "    'META': 1, 'Microsoft': 1,'Naver': 1, 'NVDIA': 2,\n",
    "    'OpenAI': 1, 'PaloAlto': 2, 'PwC': 2, 'xAI': 1,\n",
    "    'AIVerify': 0, 'ATI': 0, 'CSA': 0, 'DoS': 0,\n",
    "    'HMG': 0, 'ISOIEC': 0, 'NIST': 0, 'OECD': 0, \n",
    "    'UNESCO': 0, 'WEF': 0\n",
    "}\n",
    "\n",
    "melted_df['Frontier'] = melted_df['Framework'].map(frontier_mapping)\n",
    "\n",
    "grouped_words = melted_df.groupby(['Frontier', 'Word'])['Normalised_Count'].mean().reset_index()\n",
    "grouped_words['Frontier'] = grouped_words['Frontier'].astype(int)\n",
    "\n",
    "top_words = (\n",
    "    grouped_words.groupby('Frontier', group_keys=False)\n",
    "    .apply(lambda x: x.nlargest(8, 'Normalised_Count'))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap_data = grouped_words.pivot(index = 'Word', columns = 'Frontier', values = 'Normalised_Count').fillna(0)\n",
    "\n",
    "plt.figure(figsize = (10, 8), dpi = 500)\n",
    "sns.heatmap(heatmap_data, annot = True, \n",
    "            fmt=\".4f\", cmap=\"Oranges\", \n",
    "            cbar_kws={'label': 'Normalised Count (%)'}, \n",
    "            vmin=0, vmax=heatmap_data.values.max() * 1.5,  \n",
    "            #linewidth = 0.3, \n",
    "            #linecolor = \"black\"\n",
    ")\n",
    "plt.title('Term Frequency Heatmap Among Frameworks (Normalised)')\n",
    "plt.ylabel('Term')\n",
    "plt.xlabel('Framework Publisher')\n",
    "plt.xticks(ticks = [0.5, 1.5, 2.5], labels = ['AI Governance and Standards Bodies', 'Frontier AI Companies', 'AI-Adopting/Enterprise AI Companies'])\n",
    "plt.tight_layout()\n",
    "\n",
    "# plt.savefig()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fwenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
